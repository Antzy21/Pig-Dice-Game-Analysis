\documentclass[a4paper,titlepage]{article}
\usepackage[]{mcode}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage[margin=2cm]{geometry}
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}

\begin{document}

\begin{titlepage}
	\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
	\center

	%------------------------------------------------
	%   Logo
	%------------------------------------------------

	\includegraphics[width=0.2\textwidth]{Crest.jpg}\\[1cm]

	%------------------------------------------------
	%	Headings
	%------------------------------------------------

	\textsc{\LARGE University of Exeter}\\[1.5cm]

	\textsc{\Large College of Engineering, Mathematics and Physical Sciences}\\[0.5cm]

	\textsc{\large ECM3735 - Group 8}\\[0.5cm]

	%------------------------------------------------
	%	Title
	%------------------------------------------------

	\HRule\\[0.4cm]

	{\huge\bfseries Finding the optimal strategy for the dice game `Pig'}\\[0.4cm]

	\HRule\\[1.5cm]

	%------------------------------------------------
	%	Authors
	%------------------------------------------------

	\LARGE\textit{Authors}\\
	\begin{minipage}{0.4\textwidth}
		\begin{flushleft}
			\large
			S. \textsc{Bayliss}\\
			A. \textsc{Dunford}\\
			E. \textsc{Morison}\\
			J. \textsc{Peet}\\
			L. \textsc{Sutton}
		\end{flushleft}
	\end{minipage}
	~
	\begin{minipage}{0.4\textwidth}
		\begin{flushright}
			\large
			C. \textsc{Crawford}\\
			R. \textsc{Jones}\\
			C. \textsc{Nash}\\
			A. \textsc{Smith}
			\vspace*{10pt§}
		\end{flushright}
	\end{minipage}

	\vfill\vfill
	\textit{Supervisor}\\
	Dr. B. \textsc{Cooper}

	%------------------------------------------------
	%	Date
	%------------------------------------------------

	\vfill\vfill\vfill

	{\large\today}
	\vfill

	%------------------------------------------------
	%	Abstract
	%------------------------------------------------

	\newpage
	\begin{abstract}
	\textit{Insert abstract here}
	\end{abstract}
\end{titlepage}

	%------------------------------------------------
	%	Contents
	%------------------------------------------------

\tableofcontents
\newpage

\section{Introduction}

\subsection{Aims and Objectives}
The ultimate aim of this project was to find an optimal strategy (or optimal strategies) for the dice game ‘Pig’. The optimal strategy is to be defined as a strategy that when played against all other strategies, it has the highest probability of winning. The other aims of the project were to compare our optimal strategy found to the optimal strategy that Todd Neller describes in his 2004 paper\cite{neller2004optimal}. Finally, we looked at the psychological aspect of playing pig and whether human players play according to their risk preferences (risk neutral, risk loving or risk averse) and whether an individuals strategy is influenced by how well his opponent is.

We tried to achieve these aims by pursuing the following objectives:

\begin{enumerate}
\item Using MATLAB to create and develop a code that finds the optimal strategy firstly for piglet and then adapting this for ‘Pig’

\item Once the code for the optimal solution had been created we then used MATLAB again to create a code that takes two given ‘optimal strategies’, compares them against each other and determines which one has the statistically highest probability of winning when played multiple times. This enables us to determine which of the optimal strategies is statistically the best. 

\item Get a sample of people to play pig, get them to record their results and then determine whether their strategy is influenced by how well (or badly) their opponent is doing and whether they stick to their stated risk preferences (risk averse, risk neutral, risk loving) 
\end{enumerate}

\subsection{Basics of Pig}
`Pig' is a turn based dice game played by 2 people rolling a die. The number on the die signifies the points gained on that roll,
which are collated in a sum total of points for the turn. These points can be banked to bring a players turn to an end.
However, the points in this rolling total can be lost if the player rolls a $1$, this will also automatically bring their turn to an end.
The aim of the game is to be the first player to have a banked total of points greater than or equal to $100$.
\\
\\
Many different strategies can be used in Pig. For example, a simple strategy would be to roll until passing a turn score of 20, then banking.
A strategy can be thought of as the choice to either roll the dice, or bank the turn score, at any game state.

A game state is defined by the current position of the game, my banked score, your banked score, and my turn score.
These three scores vary between zero and 100. The mistake would be to assume that this means there are $100\times100\times100 = 1$ Million
game states. The reason this is not true is because many are not possible. Take a banked score of $90$ and a turn score of $50$ for example,
this game would have ended a long time ago when the player reached a turn score of $10$ winning them the game! This could be called an impossible
game state, because it is not possible to reach this state, playing by the rules of the game. Another type of impossible game state is
with a turn score of $1$. The smallest turnscore larger than $0$ that a player can have is by rolling a $2$, giving them a turn score of $2$.

Let us now define a strategy as an array of choices, 1s for rolling, and 0s for banking, where the array is 3 dimensional, and containing every
possible game state.
Does this let us define every possible strategy or are there more variables to consider?
If this does define every strategy, the next big question, and the main focus of this paper, is what is the best strategy to play?
What strategy is most likely to win against any other, and be crowned the Optimal Strategy for the dice game pig.

At any gamestate it is possible to produce linear equations to determine if it is better to roll or bank by looking at the probability of winning from that gamestate.
Suppose I have 2 strategies A and B. Consider that it is A's turn and we are in position ($i,j,k$) where $i$ is A's banked points,
$j$ is B's banked points, and $k$ is A's sum total of points so far on this turn. Let $P_{ijk}$ denote the probability of A winning
from the current position and $Q_{jik}$ denote probability of B winning from the equivalent position (Note that the position of $j$ and $i$ have swapped because it is
from the perspective of each player). Then,
\begin{equation}\label{1.2.1.a}
p_{ijk} = \dfrac{1}{6} (1-Q_{ij0}) + \dfrac{1}{6}\sum^{6}_{r=2}P_{ijk+r}
\end{equation}
 if A rolls and
 \begin{equation}\label{1.2.1.b}
 p_{ijk} = 1-Q_{jik}
 \end{equation}
 if A banks their points. A detailed explanation of these equations will be provided later on.

 These equations and this way of thinking about gamestates and strategies is key to our exploration further for an optimal strategy.

\subsection{Nellers Work}
In \textit{Dice Games Properly Explained}, Reiner Knizia takes the view of each roll of the die in `pig' as a bet of not rolling a $1$.
He viewed the best strategy as ``Whenever your accumulated points are less than 20, you should continue throwing, because the odds are in your favour.''\cite{knizia2010dice}.
However, Todd W Neller stated ``\textit{risking points is not the same as risking the probability of winning.}''\cite{neller2004optimal},
from this Neller proceeded to find a more optimal solution for `pig' by taking the maximum of equation \ref{1.2.1.a} and equation \ref{1.2.1.b}.
This was not possible however as he ended up with an equation of the form $x=$max$ (A_1 x+b_1,A_2 x+b_2)$ for which there is no known general method.
As a result Neller implemented value iteration to calculate an accurate estimate for the probabilities at each position $(i,j,k)$ for both bank and roll.
Figure \ref{figure1} shows the resulting optimal strategy where you should roll if you are below the surface of the graph and bank if above.

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{neller_optimal_solution}
\caption{roll\slash hold boundary for the optimal Pig play policy (Neller)\label{figure1}}
\end{figure}
\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{neller_optimal_solution_2}
\caption{all of the states reachable by an optimal player (Neller)\label{figure2}}
\end{figure}


\subsection{Optimal Stratergy}
An optimal strategy is the strategy that when played against all other strategies is the best all-rounder.
It will beat most others more than half the time however may have a few weaknesses.
In the game of rock, paper, scissors, the optimum is to play each of the three choices about a third of the time.
However, in some game the optimum is to do something destructive. The optimum is not set out to get the best
win ratio but instead it wants to minimise the maximum loss an opponent can impose on it.
In the world of pig there is a man called Todd W. Neller, who has 3 published papers on the matter.
One of them is all to do with the optimal strategy for the game of pig. As such the programme looks at all possible
game states within the pig dimension and at each node picks the one with the highest win likelihood.
We aimed to look at this in order to see whether we could get to Neller’s optimal with our own code,
or perhaps we get to a different optimal that may be better than Neller’s.
The other possibilities for the optimal was to reach a pair of strategies that when played together existed in a Nash equilibrium.
A Nash equilibrium (named after Jordan Nash) is a point in a game space at which two strategies have to get worse against there opponent
in order to adapt from their current position. Because of this it would not be optimal to follow such a path and so they stay stuck in that state.
A good example of this is the prisoners game. It is defined as the following: \\
\textit{If you confess and your accomplice fails to confess, then you go free. If you fail to confess but your accomplice confesses, then you will be convicted and sentenced for the maximum term in jail. If you both confess, then you will both be convicted, but the maximum sentence will not be imposed. If neither confess, you will both be framed for another crime in which a conviction is certain.}\\

\begin{figure}
\centering
\includegraphics{prisoners_dilemma}
\caption{Prisoner's dilemma diagram\label{figure3}}
\end{figure}

As you can see the best outcome for each is that of no confession. However this is when one prisoner would look and say that confessing is the better
option for them and then does so. Because this scenario is played such that both prisoners cannot discuss it then they would both make this discussion
and you are left with the top left box after just a quick step. As you can see, this is not the best outcome for each of them, but they would have to
take a greater loss in order to reach the best outcome and so are stuck in this nash equilibrium.
\subsection{Preliminary Findings}
chris N

% Playing the game together

\section{Methodology}
\subsection{Group Organisation}
Mia
\subsubsection{Meetings}
\subsubsection{Creation of Project Plan}

\subsection{Coding}
\subsubsection{Similataneous Equations}

As discussed briefly in the introduction, linear equations can describe the probability of winning from any given gamestate.
This is a powerful method of calculation that Nella used to produce his optimal and we used for all of the programmed strategies we produced.
As in the introduction, let $P_{i,j,k}$ denote the probability of player A winning
from the game state $i,j,k$.

Firstly let us look at the probability of A winning when banking.
A is passing to B's turn by banking. So $P^{bank}_{i,j,k}$ will be equal to the probability A has on B's turn.
The probability $Q_{j,i,k}$ is the probability the player B has of winning \textit{on their turn} at their gamestate $j,i,k$.
As Pig will have that either player will always win, so long as the game is finite, the sum of the probabilities from both players at any point in the game will be 1.
Note that this is from any point in the game, not at any gamestate, as a gamestate is specific to a player.
From this we conclude that when it is player B's turn at gamestate $j,i,k$, player A will have a probability of winning that is $1-Q_{j,i,k}$.
By banking, A add's their turn score to their banked score, and B's turn starts with a turn score of zero.
Thus we can define the probability A has at any gamestate by banking as
\begin{align*}
P^{Bank}_{i,j,k} = 1-Q_{j,i+k,0}
\end{align*}

Take the probability of A winning when rolling.
\begin{align*}
P^{Roll}_{i,j,k} = \dfrac{1}{6} (1-Q_{j,i,0}) + \dfrac{1}{6}\sum^{6}_{r=2}P_{i,j,k+r}
\end{align*}
The first part on the right side of the equation is when a 1 is rolled. Similarly to banking, when a 1 is rolled the game passes to B so the probability will be in terms of $Q_{j,i,0}$.
The main differences being that the turnscore is not added to the banked score, as can be seen in the gamestate, and there is only a $\frac{1}{6}^\text{th}$ chance of it happening.
The second part on the right is the sum of all the other possibile outcomes of rolling. Again each roll outcome has a $\frac{1}{6}^\text{th}$ chance of happening.
The results take A to new gamestates, with a higher turn score. $r$ represents the different scores that can be added, ranging from $2$ to $6$ depending on the number rolled.

How do we find out the useful probabilities that we have produced notation for?
To explain it clearly, we will look at trivial probabilities and very simple calculations.
The following equation gives the probability of winning from the gamestate where the banked score of player A is 100. By the rules of the game, A has won, meaning this probability is equal to $1$.
\begin{align*}
	P_{100,0,0}=1
\end{align*}
This is one of many trivial gamestate probabilities that are important to understand. Another would be
\begin{align*}
	P_{82,0,20}=1
\end{align*}
Where player A has accumulated enough turn score to immediatly bank and win.
Generaly, if $i+k\geq100$ and $j<100$ then the probability of that gamestate is $1$, as it means the player has won.
On the otherhand, take the following gamestate probability from A's perspective.
\begin{align*}
	P_{99,100,0}=0
\end{align*}
This gamestate is where the opponent has won the game, so player A has 0 probability of winning. A shame indeed as A was so close to winning on $99$!
Generaly, if $i<100$ and $j\geq100$, then the probability of that gamestate is $0$, as it means the other player has won.

These trivial gamestate probabilities allow us to calculate the non trivial probabilities of a game.
Let us start with a simple one, near the very end of the game. Both of the players are on $99$ points, and it is the beginning of player A's turn.
Let us assume that both A and B roll on gamestate $99,99,0$.
It may seem an obvious choice, as they have no turn score to loose, but the idea of banking on a turn score of zero is something we shal be investigating further.
\begin{align*}
	P_{99,99,0} &= \frac{1}{6}\bigg((1 - Q_{99,99,0}) + P_{99,100,2} + P_{99,100,3} + P_{99,100,4} + P_{99,100,5} + P_{99,100,6}\bigg)
\end{align*}
From what we know about trivial probabilities, we see that if A successfully rolls, i.e. doesn't roll a 1, they win the game!
So we can write the probabilities as followed, filling in the trivial probabilities.
\begin{align*}
	P_{99,99,0} &= \frac{1}{6}\bigg((1 - Q_{99,99,0}) + (1) + (1) + (1) + (1) + (1)\bigg)\\
	P_{99,99,0} &= \frac{1}{6}(1 - Q_{99,99,0})+\frac{5}{6}\\
	P_{99,99,0} &= 1 - \frac{1}{6}Q_{99,99,0}
\end{align*}
Similarly for B's turn
\begin{align*}
	Q_{99,99,0} &= \frac{1}{6}\bigg((1 - P_{99,99,0}) + Q_{99,100,2} + Q_{99,100,3} + Q_{99,100,4} + Q_{99,100,5} + Q_{99,100,6}\bigg)\\
	Q_{99,99,0} &= \frac{1}{6}\bigg((1 - P_{99,99,0}) + (1) + (1) + (1) + (1) + (1)\bigg)\\
	Q_{99,99,0} &= \frac{1}{6}(1 - P_{99,99,0})+\frac{5}{6}\\
	Q_{99,99,0} &= 1 - \frac{1}{6}P_{99,99,0}
\end{align*}

Now the two equations can be solved similtaneously, getting the results
\begin{align*}
	P_{99,99,0} &= \frac{6}{7}\\
	Q_{99,99,0} &= \frac{6}{7}
\end{align*}

This example is one complete set of similtanious equations. It turns out that every probability can be collected into a set of equations to be calculated.
Whereas this one only contained two unknowns to be solved together, others may be much larger!
Moving onto a more complicated similtaneous set, start from A's turn at game state $97,99,0$. Let A's strategy be to roll at this game state.
\begin{align*}
	P_{97,99,0} &= \frac{1}{6}(1 - Q_{99,97,0})+\frac{1}{6}P_{97,99,2}+\frac{4}{6}\\
\end{align*}
After writting this out we see the other probabilities it relies on. The method now is to see what the strategy does at those gamestates and then write out the probability equations for them.
In this example let A roll at $97,99,2$ and B roll at $99,97,0$
\begin{align*}
	P_{97,99,2} &= 1 - \frac{1}{6}Q_{99,97,0}\\
	Q_{99,97,0} &= 1 - \frac{1}{6}P_{97,99,0}\\
\end{align*}
Now we have all three similtaneous equations that can be solved.
\begin{align*}
	P_{97,99,0} &= 0.8325\\
	P_{97,99,2} &= 0.8565\\
	Q_{99,97,0} &= 0.8612
\end{align*}
This looks good so far! Does this mean we can run through all the sets of equations now?
Not just yet! First of all we must look at the interesting case of banking. Say for example instead of rolling at $97,99,2$, A banks.
The equations are now
\begin{align*}
	P_{97,99,0} &= \frac{1}{6}(1 - Q_{99,97,0})+\frac{1}{6}P_{97,99,2}+\frac{4}{6}\\
	P_{97,99,2} &= 1 - Q_{99,99,0}\\
	Q_{99,97,0} &= 1 - \frac{1}{6}P_{97,99,0}\\
\end{align*}
We do not need to write out the equation for $Q_{99,99,0}$ because we already calculated it in our first example! Its value was $\frac{6}{7}$.
So with this we can again solve the equations, getting a much different result.
\begin{align*}
	P_{97,99,0} &= 0.7102\\
	P_{97,99,2} &= 0.1429\\
	Q_{99,97,0} &= 0.8816
\end{align*}
From this we conclude that when a strategy banks, it relies on knowledge of the probabilities of gamestates nearer the end of the game than it, which we shal call "higher gamestates".
Note that it will not rely on gamestates "lower" than it.
So long as we solve the sets containing higher gamestates first, we can to run through and solve them all successfully!
\\
\\
To reiterate the power this gives us. We can calculate every probability of winning from every gamestate for every type of strategy. Actualy doing these calculations by hand is a rediculous task however.
Computational power is required to give us the probability values we want to calculate. This is where we turn to matlab for assistance.

\subsubsection{Matrices}
To make use of Matlab, we needed to write the equations in terms of matrices.
Every set of equations translates to three matrices, written $CX=D$; The coefficients, the probabilities, and the contant values respectively.
To see how these matrices are built, we will take the examples used earlier.

The first important part is to simplify the equations down. We want them in terms of seperated probabilities and their coefficient values on the left hand side of the equation, and a combined constant value on the right.
This usualy involves expanding brackets and adding constants together.\\
So
\begin{align*}
	P_{99,99,0} &= \frac{1}{6}\bigg((1 - Q_{99,99,0}) + 1 + 1 + 1 + 1 + 1\bigg)\\
	Q_{99,99,0} &= \frac{1}{6}\bigg((1 - P_{99,99,0}) + 1 + 1 + 1 + 1 + 1\bigg)\\
\end{align*}
becomes
\begin{align*}
	P_{99,99,0} + \frac{1}{6}Q_{99,99,0} &= 1\\
	Q_{99,99,0} + \frac{1}{6}P_{99,99,0} &= 1
\end{align*}

Using basic ideas of matrix multiplication, we can construct a Matrix
\begin{align*}
	\begin{bmatrix}
	    1          & \frac{1}{6}\\
	    \frac{1}{6} & 1
	\end{bmatrix}
	\begin{bmatrix}
		P_{99,99,0}\\
		Q_{99,99,0}
	\end{bmatrix}
	=
	\begin{bmatrix}
		1\\
		1
	\end{bmatrix}
\end{align*}
This is useful as we can now take the inverse of the coeefficients matrix, using it in left matrix multiplication to find the probabilities.
\begin{align*}
	C^{-1}CX &= C^{-1}D\\
	X        &= C^{-1}D
\end{align*}
Matlab has a function that does this for us, giving the probability values in the matrix $X$.
Looking at the other two examples:\\
A rolling on $97,99,2$.
\begin{align*}
	P_{97,99,0} + \frac{1}{6}Q_{99,97,0} - \frac{1}{6}P_{97,99,2} &= \frac{5}{6}\\
	P_{97,99,2} + \frac{1}{6}Q_{99,97,0}                          &=  1\\
	Q_{99,97,0} + \frac{1}{6}P_{97,99,0}                          &= 1\\
	\begin{bmatrix}
		1           & \frac{1}{6} & -\frac{1}{6}\\
		\frac{1}{6} & 1           & 0\\
		\frac{1}{6} & 0           & 1\\
	\end{bmatrix}
	\begin{bmatrix}
		P_{97,99,0}\\
		P_{97,99,2}\\
		Q_{99,99,0}
	\end{bmatrix}
	& =
	\begin{bmatrix}
		\frac{5}{6}\\
		1\\
		1
	\end{bmatrix}
\end{align*}
A banking on $97,99,2$.
\begin{align*}
	P_{97,99,0} - \frac{1}{6}P_{97,99,2} + \frac{1}{6}Q_{99,97,0}) &= \frac{5}{6}\\
	P_{97,99,2}                                                    &= 1 - Q_{99,99,0}\\
	Q_{99,97,0} + \frac{1}{6}P_{97,99,0}                           &= 1\\
	\begin{bmatrix}
		1           & \frac{1}{6} & -\frac{1}{6}\\
		0           & 1           & 0\\
		\frac{1}{6} & 0           & 1\\
	\end{bmatrix}
	\begin{bmatrix}
		P_{97,99,0}\\
		P_{97,99,2}\\
		Q_{99,99,0}
	\end{bmatrix}
	& =
	\begin{bmatrix}
		\frac{5}{6}\\
		1 - Q_{99,99,0}\\
		1
	\end{bmatrix}
\end{align*}

Notice how $Q_{99,99,0}$ is in the constant values matrix. As discussed before this is because its value should be pretermined from a previous solved similtaneous set.


% Outline how to solve for the probabilities by similitanious equations.

\subsubsection{Piglet}
When starting out on this project we were informed about a simpler version of pig, known as piglet. This is a version of pig
where by players take it in turns, flipping a coin until either a tail is flipped, or the player banks their turn score.

This simpler game contained all the same elements as pig but on a smaller scale. For starters it is a played with a coin rather than a die,
giving most probabilities as $\dfrac{1}{2}$ or multiples thereof, as opposed to the $\dfrac{1}{6}$ that you obtain via a die.
The other difference is that you typically only play to a score of $10$ compared to $100$ in pig.
These most simple of rule changes changed how the game works by a significant amount. % Disagree with this statement A LOT.
% The whole point is that it doesn't change how to game works so we can understand it and thus understand pig. Consider removing this sentence completely and check that what it is saying is not implied throughout the rest of the paragraph - Anthony
Since with a coin you may only score $1$ per flip meaning you must flip a minimum of $10$ times for you to reach you end goal. In pig this is not the case as you can roll anywhere from $2$ to $6$ points on a successful roll, giving you a minimum of $17$ rolls to achieve your goal. Having a change in the minimum number of flips allows luck to have a much greater presence in the outcome of the game, as we observed upon playing it ourselves. All of this made piglet the perfect first stepping stone to solving pig.

\subsubsection{Hand Written notes}
Since we had noticed pig was simpler we chose to use it as a way to achieve our first solution. We took pig and had it played to a total score of $3$. We played two strategies against each other; Strategy A was to bank on a turn score of $1$; Strategy B was to bank on a turn score of $2$; with both strategies banking as soon as they got over the winning score. From this we calculated all the simultaneous equations. This starts at the set that considers what the game state $P_{2,2,0}$ where by each strategy wins on its next go. These were solved using matrices like the one below.
%INSERT PICTURE OF MATRICES
From this we worked down through all possibilities to obtain the probabilities of each strategy winning from $P_{0,0,0}$ given they went first. This was the first theoretical answer we had achieved and had no idea of its validity.

We repeated this process for a game to total score $2$ with both strategies being bank at $1$. We achieved another answer which looked relatively correct. As a group we noticed a pattern at this point to which the number of sets of simultaneous equations is that of the total score squared. It was here it was realised that working our piglet to $10$ would require $100$ sets of equations for which too much time would be wasted.

\subsubsection{Writing code}

% Required knowledge:
% - Similataneous equation sets
% - Matrix form of the sets

Once we had familisirised ourselves with the rules of the game, the equations, and
a few simple piglet examples, we moved to matlab.
The end goal is the make use of Matlab's computational power, to solve thousands of
similtaneous equations and find all the probabilites at each game state.
We can also make use of variable inputs to compare any strategy to another, and
even change the score needed to win and the dice probability.

Our first attempt at simply getting out ideas down as code was a very simplified
calculation of piglet. Although we coded in a dice probability variable that could be changed,
the code only worked for a dice flip, and when the variable was set to $\frac{1}{2}$.
It was also limited to taking in only Bank on strategies.
%Explain what Bank on strats are
We could however run to any winning score.

The way we got Matlab to solve the sets of similtanious equations was by turning them into
matrices of coefficients, variables and constants. $CX=D$ This was discussed before
and will be touched on again to talk about the layout of the matrices in the more general
refined code for pig.

By using the hand calculated simple piglet probabilities we could check to see if our
coded matrices were correct and fix any bugs. Once this was working we had our first
runnable code to get us going. We just had to generalise the code.
There were two steps to doing this; taking any strategy as an input, and having any
dice probability working in the code. The former was easier; an independent problem that we
made a function to do for us. The later was a little trickier but was a fundamental part
of building the matrices.

% Subsection on Strategies to matrices

% Subsection on coding matrices

...

Once we had done this, we had a generalised working code that could calculate the
probabilities of winning at any game state, for any two strategies, for any given
dice proability and to any winning score.

\subsubsection{Testing the code}

% Rhodri

To test the output of the code, we compared the calculated probabilities to experimental results. It was sufficient to test only the value in the lowest position in the matrix, $P_{0,0,0}$, since this value relies on the higher game-states (and therefore any errors in higher positions should be reflected in this output).

$P_{0,0,0}$ represents strategy A's probability of winning at the start of the game, assuming strategy A is the first to roll. To test this value, we simulated a series of games of pig with strategy A always being the first to roll, and outputted the number of wins for strategy A. For example, our $P_{0,0,0}$ for the input strategies ``bank on 20'' and ``bank on 21'' was 0.542626, indicating that ``bank on 20'' has a 54.26\% chance of beating ``bank on 21'' when going first. Running 1,000 series of 1,000 games gave us a distribution for the number of wins for ``bank on 20'' displayed in figure %ummm number?
. The median on the boxplot is very close to the projected probability which indicated that our code had correctly calculated $P_{0,0,0}$.

% Figure goes here please Liam :)

We similarly tested some more simple strategies with successful results. Then we tried to create awkward strategies that would test the limitations of our program. Of special interest were strategies that involved banking at turnscore 0, i.e. ``skipping'' a turn. In certain circumstances this decision could theoretically lead to a stalemate, where both strategies refuse to roll. While this would never happen in practical play, it was important to equip our Matlab script to deal with these scenarios so that it wouldn't cause issues when we later come to computer-generated strategies.

A particularly interesting example is a strategy which skips a turn whenever the two players' banked scores are equal. (For convenience we exclude the starting game-state where both players have score 0.) When this strategy plays against itself, around a quarter of games result in stalemates. But because the majority of games resulted in victories for one player, we still wanted to be able to analyse this strategy, and therefore had to update the code to accommodate stalemates.

The goal was that a stalemate would be counted as a loss for both players, since this is not a desirable outcome for our optimal strategy. Our modification therefore had the entire code run twice if a stalemate was detected. On the first run, every stalemate was declared a victory for player B (hence a loss for player A) to give an accurate recording of $P_{0,0,0}$. On the second run, we reverse the order of the strategies so that stalemates are counted as a victory for player A (hence a loss for player B), giving us an accurate value for $Q_{0,0,0}$.

Adjusting the script for simulating series of games to output the number of stalemates, we could then accurately test the $P_{0,0,0}$ and $Q_{0,0,0}$ values for strategies involving skips. Now satisfied that our code gave reliable outputs for any input strategies, we were ready to use this script to compare optimal strategies.

\subsection{Behavioural Economics}
Mia and Josh

\subsection{Statistical Testing}
\subsubsection{Fair test}
Throughout our project, we will be testing numerous different strategies against one and other to determine whether a strategy is better than another. To do this accurately, we will need to ensure that the test we conduct is fair and will give a reliable result. This will be particularly important for our final findings when we want to test our version of the optimal strategy. We will want to know whether it is an optimal strategy or whether there are still some strategies that are able to beat it, meaning it isn’t `the' optimal.\\ \\
To determine whether a strategy is better than another is not as simple as playing them against each other once and deciding that the winner is the better strategy. A strategy will have a theoretical probability of winning against another given strategy, but playing only one game may not give a reliable result. Say you were to play the same strategy against itself.  The theoretical probability of either strategy winning would be $0.5$, if you were to alternate which goes first and to play a numerous amount of games. By playing only one game you would deduce that one of the strategies is better than the other even though they are the same strategy. You could also play two strategies where one has a significantly larger theoretical probability of winning than the other, but the test could conclude that the worse strategy wins, meaning you would accept that the lesser strategy is better even though theoretically it is not. This false result will be due to statistical inference.\\ \\
In the world of stats, theoretical probabilities don’t always agree with the practical results, though there are ways where you can improve the accuracy of a practical test to make it more accurate, closer to its theoretical probability. That is the point behind the fair test, to try and get a result that’s accurate to within a certain confidence of the theoretical results.  In our case, we can increase the number of games we play so that inference is reduced, therefore giving a reliable score when testing strategies.  Instead of playing only 1 game, we can play numerous games and then take scores. Say we played $100$ games, each individual game of pig will result in a winner which will result in that strategy receiving a score of $1$. This will be continued until $100$ games are complete and the probability for each strategy would be their score divided by $100$, in this case.\\ \\
The true $n$ value will need to be calculated and not decided. To do so we can use hypothesis testing. From theoretical probability values, we can define an interval around the value for which we want the practical result to lie in. The practical test will involve playing $N$ amount of games of pig were a strategy receives a score of $1$ for each game they win. After $N$ games have been completed, we can calculate the probability of the strategy winning against the other by dividing the number of games it has won by the total number of games. Then we can test numerous results for different values of $N$ and observe the distribution of $p$ as $N$ increases. From there we can chose an appropriate value for the number of games which will give us constant results within our confidence interval. Once this value has been obtained, the testing of strategies should result in reliable results and therefore be as fair of a test as possible.
 \subsubsection{Deciding that a strategy is better than another}
As mentioned before, to decide that one strategy is better than another is not as simple as playing one game of pig and saying that the victor is a better strategy.\\ \\
Once we have decided on a value for $N$ at which we decide that the test is fair, it will follow immediately what results will conclude that one strategy is better than another. By finding $N$, we will have chosen an upper and lower limit of the $p$-value at which we want our results to lie within. To illustrate this, say we conclude that $100$ games of pig is a form of a fair test and we want our practical probability to lie within $0.1$ of the true (theoretical) probability. If we were to test the same strategy against itself, theoretically either strategy should win with a probability of $0.5$, therefore after performing practical tests, we will want the representative probability to lie within $0.4$ and $0.6$. As the probability will be calculated by dividing the number of wins a strategy had and dividing it by the total number of games, we can then either perform this calculation to find the representative probability or we can calculate directly from the confidence interval how many games a certain strategy will need to win in order to conclude that it is a better strategy. In the above case, as it will need to have a probability higher than $0.6$ to conclude that it is a better strategy, it will therefore need to win $100\times0.6=60$ games at least in order to be considered a better strategy. 
\subsubsection{Testing our optimal}
To finalise our findings we will need to test our version of the optimal to find whether it is actually an optimal or at least as good as Neller’s\citep{neller2004optimal}, therefore we will need to run some test on it and evaluate the findings.\\ \\
We may begin our testing by playing our version of the optimal against simply hold at strategies, which have actually been found to be quite effective, even against Neller’s strategy:  Though of course, not better than it. By doing this we can decide whether it is actually better than simple hold at strategies or whether it needs adjusting before playing it against Neller’s version.\\ \\
Throughout these test we will keep to our definition of whether a strategy is better than another. Once we have succeeded in deducing that our version is better than all hold at strategies, we may then test our version against Neller’s and analyse the results. 


\section{Findings}
\subsection{Pig}
\subsubsection{Did we solve Pig}

\subsection{Behavioural Economics}
\subsubsection{Do players stick to their risk preference}
\subsubsection{Players Interactions}

\subsection{Statistical Testing}
\subsubsection{The test}
As mentioned in the methodology, to calculate the number of games required to play to perform a fair test we will use hypothesis testing.\\ \\
Let $S$ denote a certain strategy within the game of pig. 
Let $n$ denote the number of games played.
Let $X$ denote the number of games won by that strategy after $n$ games. 
As we will be playing $S$ against itself, we can say $E(X) = 
\dfrac{n}{2}$, the expected amount of games $S$ should win against itself. 
We can approximate $X$ to the binomial distribution to conduct the hypothesis test. 
$X \sim Bin(n , p=0.5)$ 
by the binomial distribution

\begin{align}
E(X) &= np & SD(X) &= \sqrt{var(X)}\notag\\
&= \dfrac{n}{2} & &= \sqrt{np(1-p)}\notag\\
& & &= 0.5\sqrt{n} \notag
\end{align}
By using the $Z$ distribution at a 95\% confidence interval $(z=1.96)$, we compute the following interval. 
\begin{align}
95\%Cl &= (\dfrac{n}{2} -1.96(0.5\sqrt{n}), \dfrac{n}{2} +1.96(0.5\sqrt{n}))\notag\\
&= (\dfrac{n}{2}-0.98\sqrt{n}, \dfrac{n}{2}+0.98\sqrt{n})
\notag
\end{align}
We would like the $p$ value that we obtain to be within $0.025$ of the true value of the probability. As probabilities range from $0$ to $1$, this would mean that the practical result is within $95\%$ of the theoretical value. For this system this implies that $0.475<p<0.525$. From the above interval for $X$, we can say that as $X=np$, using the upper and lower bounds for our $p$, we can then calculate a value for $n$, i.e. $0.475n$ would be equal to the lower bound for $X$ of the confidence interval with $0.525n$ being the upper bound.\\
I.e.
\begin{equation}
0.475n=\dfrac{n}{2}-0.98\sqrt{n}
\notag
\end{equation}
Solving this for $n$, we get that $n=1537$, and similarly for the upper bound.\\ \\
This would imply that playing a game of pig $1537$ times would end up giving a probability of the strategies winning against each other that is within 95\% of the true value. As theoretical stats is not 100\% accurate, this theory was simulated in matlab. We tested this theory by running $n$ games of pig $100$ times for a given strategy against itself, for $n$ ranging from $1$ to $4000$, and calculating the $p$-value from each of the games.\\ \\
\begin{figure}
\centering
\includegraphics[height=24cm]{stats_testing}
\caption{stats testing\label{figure4}}
\end{figure}
Figure \ref{figure4} shows the distribution of the $p$-values over the number of games played. Each point on the $x$-axis has $100$ values for the $y$-axis. The two lines on the $y$ axis at $y=0.475$ and $y=0.525$ show the confidence interval we want for $p$. The orange colour that runs through the graph shows a higher concentration of values. This graph shows that the distribution for $p$ is scattered greatly for small number of games played and converges as the number of games increases. We can see that around the $1500$ number of games played, the orange centre is located within the interval for $p$, but there are still a lot of stray values. These stray values still occur, but less often, even when the number of games is increased. By looking at the graph we can chose a value at which the majority of points lie within the interval.\\ \\
After the number of games passes $2500$, there doesn’t appear to be much decrease in the width of the distribution, so we will chose $3000$ as the appropriate number of games to play for a fair test. It would be a mistake to now only use $n=3000$ to test strategies. As the figure \ref{figure4} shows, even for high values for $n$, you can still get stray results. Therefore, like what was done in the test to find $n$, for strategies we want to compare we will take $100$ results of $3000$ games. Then we can take the average of these results to further improve the reliability of the result.
\subsubsection{Corollary}
\begin{figure}
\centering
\includegraphics[width=\textwidth]{stats_2}
\caption{stats\label{figure5}}
\end{figure}
In matlab, we tested the fair test numerous times by creating a code which ran the test $100$ times, that is, $100$ results $3000$ games played $100$ times with the average computed. Figure \ref{figure5} illustrates $1$ of the results of running this code. You can see that for $100$ results of the test, the distribution of $p$ is still very small. For this particular result, $p$ ranged from $0.4974$ and $0.5020$ which is well within our confidence interval for $p$. The mean of the results was (coincidently) $0.5$ exactly.\\ \\
The purpose of the fair test is that our practical results are accurate to within a certain degree of confidence to the theoretical results, in our case, within $0.025$. As we have coded a programme which can calculate the theoretical probabilities, we can run multiple simulations with the fair test to see how accurate our results are to the theoretical values.
\subsubsection{Testing theoretical probability values to practical values with the fair test}
We have showed that for a strategy playing against itself, playing $3000$ games $100$ times gives a reliable result for the probability of winning, but we now should ensure that this test also works for different strategies playing against itself. From using the theoretical probabilities calculated in matlab, we will run numerous tests for different strategies playing against themselves and comparing the theoretical results to the practical results obtained from the test. We will consider simple hold at strategies with this. Due to time constraints we will not compare every hold at strategy, though we will test a wide variety of hold at strategies.
\begin{figure}
\centering
\includegraphics[width=\textwidth]{stats_table}
\caption{stats\label{figure6}}
\end{figure}
Figure \ref{figure6} shows the result from $10$ different games of $2$ different strategies under the fair test. The last column shows the deviation from the theoretical values of the probability and the practical values obtained from the test. By our conditions, if the deviation is greater than $0.025$ then this would imply that the practical results aren’t consistent with the theoretical results implying that the test wasn’t reliable. As you can see the results are all less, and comfortably so, than $0.025$, therefore we can say that the test conducted gives reliable results and is therefore fair.
\subsubsection{Determining whether a strategy is better than another}
There are two ways which we could analyse the results. As we are playing $3000$ games of pig and giving each strategy a score of $1$ for each game they win, we could analyse the score for both strategies and use that to determine whether it is better or worse than the other strategy. Though we are playing $100$ independent $3000$ games and then taking the average score of both strategies, the following method will still apply.\\ \\
From looking at our maximal value for the probability in the confidence interval, as $X=np$ where $n=3000$ and $p=0.525$, we can say that if one strategy wins on average $X=3000\times0.525=1575$ then it is better than the other strategy.\\ \\
We could also look at the respective probability of the strategies from the theoretical results.  As $p=\dfrac{X}{n}$, if the value for $p$ is outside our determined confidence interval, we can then deduce that one of the strategies is better than the other.
\subsubsection{Statistical findings on the optimal}
It happens to be that simply hold at strategies, i.e. If your turn score is less than $20$ (say, then you always roll, are quite affective (as said by neller?). This made us think that testing our version of the optimal strategy against simply hold at strategies would be a good place to start. We could find the optimal and then play it against numerous hold at strategies and see the results, though we thought it would be good to find whether there was a best hold at strategy so that we only need to use that to analyse our version of the optimal.\\ \\
As we saw earlier, Figure \ref{figure6} shows some of the probabilities we obtained from running these tests along with their theoretical probabilities. We decided to run a test, in compliance with our rules for a fair test, in Matlab of every hold at strategy from hold at $1$ to hold at $100$ in order to determine which particular hold at strategy was better than all of the others. As we saw earlier, the strategy hold at $0$ cannot win any games it plays and so, to reduce computing time, we will not include this in our simulations. We wanted to know whether there was one hold at strategy which beat all other strategies, as opposed to finding which one won the most against the others. By this we mean whether the strategies are transitive. By saying that the strategies are transitive, we mean that if we have strategies A, B and C, where A is better than B and B is better than C, then A is better than C also. This would mean that if we find one strategy that is the best, it will beat all other strategies. We ran a Matlab simulation, again alongside our rules for a fair test, which returned a result that confirmed that these simple hold at strategies are in fact transitive.\\ \\
After we had looked at the transitivity of strategies, we looked at playing a tournament between all of the ‘hold at’ strategies from $1$ to $100$ in order to find which such strategy was the most superior and beat all of the rest. We again ran this in compliance with our rules for a fair test and the outcome of this tournament was that hold at $25$ came out to be victorious from $10$ tournaments.
\subsubsection{Interesting note}
After we evaluated all of the simple hold at strategies, we decided to look at more complicated strategies that have other rules other than just at what turn score to bank at. When evaluating strategies of this description, we were able to find three strategies that are non-transitive. The strategies we have found that have such properties are named turtle, roll to win and roll and wait. Turtle is a slow strategy, as suggested by its given name, banking on a low score each turn and thus slowly making its way towards $100$. Roll to win is a very simple strategy, where it only banks once the turn score reaches $100$. Roll and wait is a strategy that behaves such that it gets up to a banked score of $80$, before not rolling and waiting for the opponent to catch up, before then rolling to try to win. We ran fair tests between these strategies and have found both practical and theoretical probabilities of each strategy winning against another. When turtle played against roll to win, we got a practical probability that turtle will win with probability of $0.8127$ when going first, compared to $0.1949$ for that of roll to win. Comparatively, we get theoretical probabilities of $0.812840$ for turtle to win going first and $0.195448$ for roll to win. Using these number to calculate who wins in general from multiple games is fairly simple and will be explained further on, but the calculate to be $0.8089$ for turtle winning and $0.1911$ for roll to win to win. This is again showing that our tests are accurate, with very little deviation between the practical and theoretical values. This shows that turtle is a better strategy as both the practical and theoretical probabilities of it beating roll to win lie above $0.525$, the upper bound of our previously stated confidence interval. Similarly, roll to win’s probability lies below the lower bound of $0.475$, further confirming our conclusion that turtle is superior. We then played roll to win against roll and wait and got both practical and theoretical probabilities of $1$ for roll to win winning, regardless of who went first. Roll and wait produces a practical probability of beating turtle $0.7101$ when going first and $0.7062$, whereas the latter wins with probability $0.2983$ when it goes first. This compares to the practical probabilities of $0.710606$ for roll and wait and $0.297148$ for turtle. The probabilities for roll and wait to win clearly lie above the upper bound of our confidence interval, and turtle below the lower bound, hence we conclude that it is the better strategy. As this experiment shows, for both practical and theoretical probabilities, turtle is better than roll to win, roll to win is better than roll and wait, however, roll and wait is better than turtle, giving us a 3-way loop, and hence proving that these such strategies are non-transitive.\\ \\
Our function in matlab calculates the probability of a strategy winning given that it starts the game, therefore, theoretically we calculate the general probability of it beating every other ‘hold at’ strategy as follows:\\
Let $x$ denote the probability hold at $25$ winning when going first.\\
Let $y$ denote that of its opposing strategy when it goes first.\\
Let $X$ be the general probability of hold at $25$ winning.\\
For $3000$ games, hold at $25$ goes first $1500$ times and second the same amount of times, so we have 
\begin{align}
X &= \dfrac{1500(x)+1500(1-y)}{3000}\notag\\
X &= \dfrac{x+(1-y)}{2}\notag
\end{align}
As an example, let’s compare it against hold at $30$. We calculated the probability of hold at $25$ winning when going first as $0.573741$ and that of hold at $30$ as $0.48091$. If we put this in our formula, we get\\ $X=\dfrac{0.573741+(1-0.48091)}{2}=0.546416$. Applying this against all other ‘hold at’ strategies, we can produce the graph in figure \ref{figure7}.
\begin{figure}
\centering
\includegraphics[width=\textwidth]{stats_3}
\caption{\label{figure7}}
\end{figure}
As we can see in figure \ref{figure7}, all of the general probabilities for hold at $25$ winning lie strictly above the line of $y=0.5$, other than when it plays against itself, when it gives a value of $0.5$ as expected. From this, we can deduce that, theoretically, this is also the best of these simple ‘hold at’ strategies.\\ \\
Upon finding our ``optimal strategy'', we then had to test it against other strategies in order to show that it is in fact the superior of the two in question and, in turn, the best to play against any given strategy. As we saw from the tournament of all of the ‘hold at’ strategies, and the subsequent table of probabilities, hold at $25$ was the best of the simple old at strategies. As the ‘hold at’ strategies are also transitive, it made sense to test our optimal against this one and then conclude that our strategy beats all of the rest also. We ran the two against each other in line with our fair test and the simulation returned a practical probability of $0.55076$ that our optimal would win when going first and $0.52136$ in general, compared to hold at $25$ winning with probability $0.50804$ when going first and just $0.47864$ in general. As we can see our optimal strategy beats hold at $25$ when going first with a probability that lies above our confidence interval, showing that our strategy is superior. This is also in agreement of theoretical calculations, with our optimal theoretically winning $0.55127$ in general and bank at $25$ winning with probability $0.50914$. As we know that the ‘hold at’ strategies are transitive, this then means that our optimal strategy beats all such simple strategies also.\\ \\
We then tested our optimal strategy against that of Neller’s. These simulations returned results of a probability of $0.53182$ when our strategy went first and $0.53176$ when Neller’s went first, which are values within each-others confidence interval which suggest that practically the two strategies could have the same probability. This was also backed up, with theoretical results showing that both neller’s and our optimal won when going first with a probability of $0.53059$. This then gave us a general probability of each strategy winning of $0.5$, showing that our optimal strategy has in fact converged to that found by Neller previously. 

\section{Conclusions}
\subsection{Overall findings}
\subsection{Determination of human affects on the optimal stratergy}
\subsection{Statsical analysis}
To conclude statistical analysis, we first had to acknowledge that probabilities for our strategies winning could be measured both practically and theoretically and these can often differ greatly. In order to ensure that these were as close as they could be, we needed to create some rules for a fair test by which we would have to follow when playing two strategies against each other, in order to accurately compare them.\\ \\
We first noted that a particular strategy will win against itself with a general probability of $0.5$. We then constructed a confidence interval at the $95\%$ significance level with the idea that we didn’t want $p$ to differ more than $0.025$ away from $0.5$, where $p$ denotes the probability of a strategy winning against itself. From this, we could work backwards from our confidence interval and find the optimal number of games, $n$, required for one single fair test. This method produced $n=1537$. However, we saw from figure \ref{figure4} that this value of $n$ gave too many outliers in the data, so we instead chose $3000$ as it appeared accurate for our particular confidence interval. As this number still produced some outlying data, we decided to run $100$ fair tests in order to minimise the error as much as we could in order to obtain accurate practical probabilities against theoretical ones. \\ \\
We decided first to look at simple ‘hold at’ strategies and found them to be transitive. By this, we mean, for three strategies A, B and C, if A is better than B and B is better than C, then A is better than C. This means we could have one strategy superior than the rest and we found this to be hold at 25, when we ran a tournament between the strategies.\\ \\
We were then required to test if the optimal strategy that we thought we had found was in fact superior. As we knew the ‘hold at’ strategies to be transitive, we only needed to test it against the best of these in order to know that it was better than the rest, assuming that it won. Our optimal strategy won with general probability of $0.52136$, thus allowing us to conclude that it was better than all of the ‘hold at’ strategies.\\ \\
We then tested our optimal against that found by Neller\citep{neller2004optimal} to see if our strategy had in fact converged to this. Both strategies, when going first, won with the same probability of $0.53182$, giving a general probability of $0.5$ for each strategy. We could then conclude that our strategy was in fact the same as the optimal that Neller had found and written about himself. 
 
\nocite{*}
\bibliographystyle{alpha}
\bibliography{Pig_bib}
\end{document}
